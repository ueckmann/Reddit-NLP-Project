{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3 Data Collection\n",
    "\n",
    "The challenge of Project 3 is to collect data from the reddit submissions [API](https://api.pushshift.io/reddit/search/submission), which contains data from various subreddits across reddit. Our goal here is to extract a few thousand rows of data from the API to use in the project, and to export them as a csv. We'll be pulling from the r/Fantasy and r/scifi subreddits for the project. Instructions for how to utilize the API can be found on the API's [Github page](https://github.com/pushshift/api). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime as dt\n",
    "import requests\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Data\n",
    "\n",
    "According to the instructions on the github page, there are several parameters through which we can specify what we want from the API. For our purposes, we only have a few criteria - we want to specify which subreddit we want to pull from, the amount of entries, and how far back we want to go. It's also important to note that we will not be going through the comments section for this project, only submissions.  \n",
    "\n",
    "Below is a function that will abstract all the work for extracting our data from the API, while also cleaning some of it for us. We want to get as much data as possible from one consecutive timeframe, so the function will pull from a few days ago, then pull from a few days before that until it finishes iterating. The `day_window` parameter determines how many days to go back, while the `n` parameter is how many times we want to go back that many days. So, if `day_window` is set to 10, and `n` is set to 5, the function will loop through and collect 50 days worth of data. It's important to know that currently, the reddit API only allows for users to extract 100 observations per pull. Given the number of posts per subreddit, we'll have to play around with the function to determine how many days we'll need to space our extractions in order to avoid overlapping data, since we'll be pulling the max observations each time. This function extracts the data as a JSON, and converts it into a dataframe. Since we don't want to be rude and pull all our data at once, the iterations will be spaced out by a period of 2 seconds each so as not to affect the API's server, and in general, to not be rude. The function will also print out whichever set of data it is extracting each time it iterates.  \n",
    "\n",
    "Each iteration will create an new dataset with 100 rows. We'll concatenate all the datasets into one large dataset that will then be cleaned. Any overlapping data will be cleaned, and unnecessary columns will be dropped. The remaining columns will be: `title`, `selftext`,`subreddit`, `created_utc`, `author`, `num_comments`, `score`, and `is_self`. For more information on these columns, look at the data dictionary in the [README](../README.md). Because the date and time for the data is stored in epoch time, we'll also create a new column that will record the dates in normal mm/dd/yyyy format. For those interested in reproducing this project, the start date for the data is from July 20, 2020. The dataframe will also drop any removed or deleted submissions as those are not useful, as well as any empty values from the submissions. Finally, the dataframe's index is reset, giving us a clean, useable dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code here was copied from Mahdi's intro to project 3 lecture\n",
    "def query_pushshift(subreddit, kind = 'submission', day_window = 30, n = 5):\n",
    "    SUBFIELDS = ['title', 'selftext', 'subreddit', 'created_utc', 'author', 'num_comments', 'score', 'is_self']\n",
    "    \n",
    "    # establish base url and stem\n",
    "    BASE_URL = f\"https://api.pushshift.io/reddit/search/{kind}\" # also known as the \"API endpoint\" \n",
    "    stem = f\"{BASE_URL}?subreddit={subreddit}&size=100\" # always pulling max of 100\n",
    "    \n",
    "    # instantiate empty list for temp storage\n",
    "    posts = []\n",
    "    \n",
    "    # implement for loop with `time.sleep(2)`\n",
    "    for i in range(1, n + 1):\n",
    "        URL = \"{}&after={}d\".format(stem, day_window * i)\n",
    "        print(\"Querying from: \" + URL)\n",
    "        response = requests.get(URL)\n",
    "        assert response.status_code == 200\n",
    "        mine = response.json()['data']\n",
    "        df = pd.DataFrame.from_dict(mine)\n",
    "        posts.append(df)\n",
    "        time.sleep(2)\n",
    "    \n",
    "    # pd.concat storage list\n",
    "    full = pd.concat(posts, sort=False)\n",
    "    # immediately reset the index so the data frame can tell the difference between the various rows, otherwise, it\n",
    "    # can drop multiple rows when that was not intended.\n",
    "    full.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    # if submission\n",
    "    if kind == \"submission\":\n",
    "        # select desired columns\n",
    "        full = full[SUBFIELDS]\n",
    "        # drop duplicates\n",
    "        full.drop_duplicates(inplace = True)\n",
    "        # select `is_self` == True, which indicates that the submission is a text submission\n",
    "        full = full.loc[full['is_self'] == True]\n",
    "\n",
    "    # create `timestamp` column\n",
    "    full['timestamp'] = full[\"created_utc\"].map(dt.date.fromtimestamp)\n",
    "    \n",
    "    # drop any removed, deleted, or null texts\n",
    "    full.drop(index = (full.loc[full[\"selftext\"] == \"[removed]\",:].index), inplace = True)\n",
    "    full.drop(index = (full.loc[full[\"selftext\"] == \"[deleted]\",:].index), inplace = True)\n",
    "    full.drop(index = (full.loc[full[\"selftext\"] == \"\",:].index), inplace = True)\n",
    "    full.drop(index = (full.loc[full[\"selftext\"].isna(),:].index), inplace = True)\n",
    "    # reset the index one final time now that all the cleaned data is collected\n",
    "    full.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    print(\"Query Complete!\")    \n",
    "    return full "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Fantasy Subreddit\n",
    "After playing around with a few options, we determined that the fantasy subreddit reaches 100 posts every 2 days or so, and our goal was for a dataframe of about 2,500 rows. So, we collected 72 days of data, which meant that from the 3,600 original rows, about 900 rows were dropped due to being duplicates, nontext posts, or removed or deleted posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=2d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=4d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=6d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=8d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=10d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=12d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=14d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=16d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=18d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=20d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=22d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=24d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=26d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=28d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=30d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=32d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=34d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=36d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=38d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=40d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=42d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=44d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=46d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=48d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=50d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=52d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=54d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=56d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=58d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=60d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=62d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=64d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=66d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=68d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=70d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=72d\n",
      "Query Complete!\n"
     ]
    }
   ],
   "source": [
    "fantasy_df = query_pushshift(\"fantasy\", day_window = 2, n = 36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>is_self</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LF Recommendation: Fantasy with long travel ep...</td>\n",
       "      <td>Hi looking for recommendation for a top prefer...</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>1595295818</td>\n",
       "      <td>Overthrown77</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-07-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the best Fantasy book you've read that...</td>\n",
       "      <td>usually I don't enjoy something below four sta...</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>1595304562</td>\n",
       "      <td>OraclePreston</td>\n",
       "      <td>55</td>\n",
       "      <td>19</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Favorite fantasy names?</td>\n",
       "      <td>I love fantasy, and I also have a thing for na...</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>1595305376</td>\n",
       "      <td>omnomenclature</td>\n",
       "      <td>59</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anyone can recommend me a book without having ...</td>\n",
       "      <td>Idk how else to put the title but I really wan...</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>1595305716</td>\n",
       "      <td>UlyssesCourier</td>\n",
       "      <td>61</td>\n",
       "      <td>33</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It’s been 10 years since I read “The Way of Ki...</td>\n",
       "      <td>And now, here I am, a 32 year old man, chuckli...</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>1595311158</td>\n",
       "      <td>Bock_Tea</td>\n",
       "      <td>65</td>\n",
       "      <td>126</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-07-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  LF Recommendation: Fantasy with long travel ep...   \n",
       "1  What is the best Fantasy book you've read that...   \n",
       "2                            Favorite fantasy names?   \n",
       "3  Anyone can recommend me a book without having ...   \n",
       "4  It’s been 10 years since I read “The Way of Ki...   \n",
       "\n",
       "                                            selftext subreddit  created_utc  \\\n",
       "0  Hi looking for recommendation for a top prefer...   Fantasy   1595295818   \n",
       "1  usually I don't enjoy something below four sta...   Fantasy   1595304562   \n",
       "2  I love fantasy, and I also have a thing for na...   Fantasy   1595305376   \n",
       "3  Idk how else to put the title but I really wan...   Fantasy   1595305716   \n",
       "4  And now, here I am, a 32 year old man, chuckli...   Fantasy   1595311158   \n",
       "\n",
       "           author  num_comments  score  is_self   timestamp  \n",
       "0    Overthrown77            16      5     True  2020-07-20  \n",
       "1   OraclePreston            55     19     True  2020-07-21  \n",
       "2  omnomenclature            59     17     True  2020-07-21  \n",
       "3  UlyssesCourier            61     33     True  2020-07-21  \n",
       "4        Bock_Tea            65    126     True  2020-07-21  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at our dataset\n",
    "fantasy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2517 rows of data in this dataset.\n",
      "There are 9 columns of data in this dataset\n"
     ]
    }
   ],
   "source": [
    "# Confirm the size of our data\n",
    "print (f\"There are {fantasy_df.shape[0]} rows of data in this dataset.\")\n",
    "print (f\"There are {fantasy_df.shape[1]} columns of data in this dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title           0\n",
       "selftext        0\n",
       "subreddit       0\n",
       "created_utc     0\n",
       "author          0\n",
       "num_comments    0\n",
       "score           0\n",
       "is_self         0\n",
       "timestamp       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to ensure we have a complete dataset\n",
    "fantasy_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Scifi Subreddit\n",
    "Similar to the Fantasy subreddit, we determined that the scifi subreddit reaches 100 posts every 4 days or so, and our goal was for a dataframe of about 2,500 rows. So, we collected 288 days of data, which meant that from the 7,400 original rows, about 4,900 rows were dropped due to being duplicates, nontext posts, or removed or deleted posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=4d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=8d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=12d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=16d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=20d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=24d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=28d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=32d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=36d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=40d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=44d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=48d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=52d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=56d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=60d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=64d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=68d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=72d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=76d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=80d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=84d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=88d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=92d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=96d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=100d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=104d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=108d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=112d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=116d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=120d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=124d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=128d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=132d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=136d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=140d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=144d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=148d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=152d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=156d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=160d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=164d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=168d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=172d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=176d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=180d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=184d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=188d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=192d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=196d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=200d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=204d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=208d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=212d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=216d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=220d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=224d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=228d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=232d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=236d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=240d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=244d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=248d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=252d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=256d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=260d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=264d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=268d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=272d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=276d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=280d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=284d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=288d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=292d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=296d\n",
      "Query Complete!\n"
     ]
    }
   ],
   "source": [
    "scifi_df = query_pushshift(\"scifi\", day_window = 4, n = 74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>is_self</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Help needed - I’m writing a whodunit detective...</td>\n",
       "      <td>So this is my idea, At the place of crime, the...</td>\n",
       "      <td>scifi</td>\n",
       "      <td>1595143575</td>\n",
       "      <td>gooodfella</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anyone else feel Robocop 2 is underrated?</td>\n",
       "      <td>Okay, so don’t get me wrong, the original Robo...</td>\n",
       "      <td>scifi</td>\n",
       "      <td>1595151760</td>\n",
       "      <td>elflamingo2</td>\n",
       "      <td>36</td>\n",
       "      <td>52</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Looking for an cancelled space sci-fi series</td>\n",
       "      <td>Hi.\\n\\nI'm thinking of an series where it seem...</td>\n",
       "      <td>scifi</td>\n",
       "      <td>1595155987</td>\n",
       "      <td>FuriousRageSE</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Would a Halo Ring around earth work?</td>\n",
       "      <td>In theory, if you built a halo ring around ear...</td>\n",
       "      <td>scifi</td>\n",
       "      <td>1595172527</td>\n",
       "      <td>santana303</td>\n",
       "      <td>48</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trying to remember something from an old book ...</td>\n",
       "      <td>I recall many years ago I read a book or a sho...</td>\n",
       "      <td>scifi</td>\n",
       "      <td>1595178021</td>\n",
       "      <td>Vorngiburk</td>\n",
       "      <td>50</td>\n",
       "      <td>268</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-07-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Help needed - I’m writing a whodunit detective...   \n",
       "1          Anyone else feel Robocop 2 is underrated?   \n",
       "2       Looking for an cancelled space sci-fi series   \n",
       "3               Would a Halo Ring around earth work?   \n",
       "4  Trying to remember something from an old book ...   \n",
       "\n",
       "                                            selftext subreddit  created_utc  \\\n",
       "0  So this is my idea, At the place of crime, the...     scifi   1595143575   \n",
       "1  Okay, so don’t get me wrong, the original Robo...     scifi   1595151760   \n",
       "2  Hi.\\n\\nI'm thinking of an series where it seem...     scifi   1595155987   \n",
       "3  In theory, if you built a halo ring around ear...     scifi   1595172527   \n",
       "4  I recall many years ago I read a book or a sho...     scifi   1595178021   \n",
       "\n",
       "          author  num_comments  score  is_self   timestamp  \n",
       "0     gooodfella            10      0     True  2020-07-19  \n",
       "1    elflamingo2            36     52     True  2020-07-19  \n",
       "2  FuriousRageSE            22      2     True  2020-07-19  \n",
       "3     santana303            48     20     True  2020-07-19  \n",
       "4     Vorngiburk            50    268     True  2020-07-19  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the data\n",
    "scifi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2540 rows of data in this dataset.\n",
      "There are 9 columns of data in this dataset\n"
     ]
    }
   ],
   "source": [
    "# Confirm the size of our data\n",
    "print (f\"There are {scifi_df.shape[0]} rows of data in this dataset.\")\n",
    "print (f\"There are {scifi_df.shape[1]} columns of data in this dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title           0\n",
       "selftext        0\n",
       "subreddit       0\n",
       "created_utc     0\n",
       "author          0\n",
       "num_comments    0\n",
       "score           0\n",
       "is_self         0\n",
       "timestamp       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that we have a completed dataset\n",
    "scifi_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the Dataframes\n",
    "Next, we'll concatenate the 2 datasets, one on top of the other, into one large dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>is_self</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LF Recommendation: Fantasy with long travel ep...</td>\n",
       "      <td>Hi looking for recommendation for a top prefer...</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>1595295818</td>\n",
       "      <td>Overthrown77</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-07-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the best Fantasy book you've read that...</td>\n",
       "      <td>usually I don't enjoy something below four sta...</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>1595304562</td>\n",
       "      <td>OraclePreston</td>\n",
       "      <td>55</td>\n",
       "      <td>19</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Favorite fantasy names?</td>\n",
       "      <td>I love fantasy, and I also have a thing for na...</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>1595305376</td>\n",
       "      <td>omnomenclature</td>\n",
       "      <td>59</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anyone can recommend me a book without having ...</td>\n",
       "      <td>Idk how else to put the title but I really wan...</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>1595305716</td>\n",
       "      <td>UlyssesCourier</td>\n",
       "      <td>61</td>\n",
       "      <td>33</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It’s been 10 years since I read “The Way of Ki...</td>\n",
       "      <td>And now, here I am, a 32 year old man, chuckli...</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>1595311158</td>\n",
       "      <td>Bock_Tea</td>\n",
       "      <td>65</td>\n",
       "      <td>126</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-07-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  LF Recommendation: Fantasy with long travel ep...   \n",
       "1  What is the best Fantasy book you've read that...   \n",
       "2                            Favorite fantasy names?   \n",
       "3  Anyone can recommend me a book without having ...   \n",
       "4  It’s been 10 years since I read “The Way of Ki...   \n",
       "\n",
       "                                            selftext subreddit  created_utc  \\\n",
       "0  Hi looking for recommendation for a top prefer...   Fantasy   1595295818   \n",
       "1  usually I don't enjoy something below four sta...   Fantasy   1595304562   \n",
       "2  I love fantasy, and I also have a thing for na...   Fantasy   1595305376   \n",
       "3  Idk how else to put the title but I really wan...   Fantasy   1595305716   \n",
       "4  And now, here I am, a 32 year old man, chuckli...   Fantasy   1595311158   \n",
       "\n",
       "           author  num_comments  score  is_self   timestamp  \n",
       "0    Overthrown77            16      5     True  2020-07-20  \n",
       "1   OraclePreston            55     19     True  2020-07-21  \n",
       "2  omnomenclature            59     17     True  2020-07-21  \n",
       "3  UlyssesCourier            61     33     True  2020-07-21  \n",
       "4        Bock_Tea            65    126     True  2020-07-21  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df = pd.concat([fantasy_df, scifi_df], axis = 0, ignore_index= True)\n",
    "# Reset the index so there are no repeats\n",
    "reddit_df.reset_index(drop = True, inplace = True)\n",
    "# Take a look at our data\n",
    "reddit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5057 rows of data in this dataset.\n",
      "There are 9 columns of data in this dataset\n"
     ]
    }
   ],
   "source": [
    "# Confirm the size of our data\n",
    "print (f\"There are {reddit_df.shape[0]} rows of data in this dataset.\")\n",
    "print (f\"There are {reddit_df.shape[1]} columns of data in this dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scifi      2540\n",
       "Fantasy    2517\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that our 2 dataframes are in our new one\n",
    "reddit_df[\"subreddit\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title           0\n",
       "selftext        0\n",
       "subreddit       0\n",
       "created_utc     0\n",
       "author          0\n",
       "num_comments    0\n",
       "score           0\n",
       "is_self         0\n",
       "timestamp       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll double check our null values\n",
    "reddit_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export our Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export our dataframe, while not creating a new column from the index.\n",
    "reddit_df.to_csv(\"../data/subreddits.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
