{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3 Data Collection\n",
    "\n",
    "The challenge of Project 3 is to collect data from the reddit submissions [API](https://api.pushshift.io/reddit/search/submission), which contains data from various subreddits across reddit. Our goal here is to extract a few thousand rows of data from the API to use in the project, and to export them as a csv. We'll be pulling from the r/Fantasy and r/scifi subreddits for the project. Instructions for how to utilize the API can be found on the API's [Github page](https://github.com/pushshift/api). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime as dt\n",
    "import requests\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Data\n",
    "\n",
    "According to the instructions on the github page, there are several parameters through which we can specify what we want from the API. For our purposes, we only have a few criteria - we want to specify which subreddit we want to pull from, the amount of entries, and how far back we want to go. It's also important to note that we will not be going through the comments section for this project, only submissions.  \n",
    "\n",
    "Below is a function that will abstract all the work for extracting our data from the API, while also cleaning some of it for us. We want to get as much data as possible from one consecutive timeframe, so the function will pull from a few days ago, then pull from a few days before that until it finishes iterating. The `day_window` parameter determines how many days to go back, while the `n` parameter is how many times we want to go back that many days. So, if `day_window` is set to 10, and `n` is set to 5, the function will loop through and collect 50 days worth of data. It's important to know that currently, the reddit API only allows for users to extract 100 observations per pull. Given the number of posts per subreddit, we'll have to play around with the function to determine how many days we'll need to space our extractions in order to avoid overlapping data, since we'll be pulling the max observations each time. This function extracts the data as a JSON, and converts it into a dataframe. Since we don't want to be rude and pull all our data at once, the iterations will be spaced out by a period of 2 seconds each so as not to affect the API's server, and in general, to not be rude. The function will also print out whichever set of data it is extracting each time it iterates.  \n",
    "\n",
    "Each iteration will create an new dataset with 100 rows. We'll concatenate all the datasets into one large dataset that will then be cleaned. Any overlapping data will be cleaned, and unnecessary columns will be dropped. The remaining columns will be: `title`, `selftext`,`subreddit`, `created_utc`, `author`, `num_comments`, `score`, and `is_self`. For more information on these columns, look at the data dictionary in the [README](../README.md). Because the date and time for the data is stored in epoch time, we'll also create a new column that will record the dates in normal mm/dd/yyyy format. For those interested in reproducing this project, the start date for the data is from July 20, 2020. The dataframe will also drop any removed or deleted submissions as those are not useful, as well as any empty values from the submissions. Finally, the dataframe's index is reset, giving us a clean, useable dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code here was copied from Mahdi's intro to project 3 lecture\n",
    "def query_pushshift(subreddit, kind = 'submission', day_window = 30, n = 5):\n",
    "    SUBFIELDS = ['title', 'selftext', 'subreddit', 'created_utc', 'author', 'num_comments', 'score', 'is_self']\n",
    "    \n",
    "    # establish base url and stem\n",
    "    BASE_URL = f\"https://api.pushshift.io/reddit/search/{kind}\" # also known as the \"API endpoint\" \n",
    "    stem = f\"{BASE_URL}?subreddit={subreddit}&size=100\" # always pulling max of 100\n",
    "    \n",
    "    # instantiate empty list for temp storage\n",
    "    posts = []\n",
    "    \n",
    "    # implement for loop with `time.sleep(2)`\n",
    "    for i in range(1, n + 1):\n",
    "        URL = \"{}&after={}d\".format(stem, day_window * i)\n",
    "        print(\"Querying from: \" + URL)\n",
    "        response = requests.get(URL)\n",
    "        assert response.status_code == 200\n",
    "        mine = response.json()['data']\n",
    "        df = pd.DataFrame.from_dict(mine)\n",
    "        posts.append(df)\n",
    "        time.sleep(2)\n",
    "    \n",
    "    # pd.concat storage list\n",
    "    full = pd.concat(posts, sort=False)\n",
    "    # immediately reset the index so the data frame can tell the difference between the various rows, otherwise, it\n",
    "    # can drop multiple rows when that was not intended.\n",
    "    full.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    # if submission\n",
    "    if kind == \"submission\":\n",
    "        # select desired columns\n",
    "        full = full[SUBFIELDS]\n",
    "        # drop duplicates\n",
    "        full.drop_duplicates(inplace = True)\n",
    "        # select `is_self` == True, which indicates that the submission is a text submission\n",
    "        full = full.loc[full['is_self'] == True]\n",
    "\n",
    "    # create `timestamp` column\n",
    "    full['timestamp'] = full[\"created_utc\"].map(dt.date.fromtimestamp)\n",
    "    \n",
    "    # drop any removed, deleted, or null texts\n",
    "    full.drop(index = (full.loc[full[\"selftext\"] == \"[removed]\",:].index), inplace = True)\n",
    "    full.drop(index = (full.loc[full[\"selftext\"] == \"[deleted]\",:].index), inplace = True)\n",
    "    full.drop(index = (full.loc[full[\"selftext\"].isna(),:].index), inplace = True)\n",
    "    # reset the index one final time now that all the cleaned data is collected\n",
    "    full.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    print(\"Query Complete!\")    \n",
    "    return full "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Fantasy Subreddit\n",
    "After playing around with a few options, we determined that the fantasy subreddit reaches 100 posts every 2 days or so, and our goal was for a dataframe of about 2,500 rows. So, we collected 72 days of data, which meant that from the 3,600 original rows, about 900 rows were dropped due to being duplicates, nontext posts, or removed or deleted posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=2d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=4d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=6d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=8d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=10d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=12d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=14d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=16d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=18d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=20d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=22d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=24d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=26d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=28d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=30d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=32d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=34d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=36d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=38d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=40d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=42d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=44d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=46d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=48d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=50d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=52d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=54d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=56d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=58d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=60d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=62d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=64d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=66d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=68d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=70d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=fantasy&size=100&after=72d\n",
      "Query Complete!\n"
     ]
    }
   ],
   "source": [
    "fantasy_df = query_pushshift(\"fantasy\", day_window = 2, n = 36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>is_self</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are NEWLY published and noticeably popula...</td>\n",
       "      <td>I've asked the same question last year I think...</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>1595292735</td>\n",
       "      <td>uera</td>\n",
       "      <td>68</td>\n",
       "      <td>37</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-07-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LF Recommendation: Fantasy with long travel ep...</td>\n",
       "      <td>Hi looking for recommendation for a top prefer...</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>1595295818</td>\n",
       "      <td>Overthrown77</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-07-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the best Fantasy book you've read that...</td>\n",
       "      <td>usually I don't enjoy something below four sta...</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>1595304562</td>\n",
       "      <td>OraclePreston</td>\n",
       "      <td>55</td>\n",
       "      <td>19</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Favorite fantasy names?</td>\n",
       "      <td>I love fantasy, and I also have a thing for na...</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>1595305376</td>\n",
       "      <td>omnomenclature</td>\n",
       "      <td>56</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anyone can recommend me a book without having ...</td>\n",
       "      <td>Idk how else to put the title but I really wan...</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>1595305716</td>\n",
       "      <td>UlyssesCourier</td>\n",
       "      <td>61</td>\n",
       "      <td>33</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-07-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  What are NEWLY published and noticeably popula...   \n",
       "1  LF Recommendation: Fantasy with long travel ep...   \n",
       "2  What is the best Fantasy book you've read that...   \n",
       "3                            Favorite fantasy names?   \n",
       "4  Anyone can recommend me a book without having ...   \n",
       "\n",
       "                                            selftext subreddit  created_utc  \\\n",
       "0  I've asked the same question last year I think...   Fantasy   1595292735   \n",
       "1  Hi looking for recommendation for a top prefer...   Fantasy   1595295818   \n",
       "2  usually I don't enjoy something below four sta...   Fantasy   1595304562   \n",
       "3  I love fantasy, and I also have a thing for na...   Fantasy   1595305376   \n",
       "4  Idk how else to put the title but I really wan...   Fantasy   1595305716   \n",
       "\n",
       "           author  num_comments  score  is_self   timestamp  \n",
       "0            uera            68     37     True  2020-07-20  \n",
       "1    Overthrown77            16      5     True  2020-07-20  \n",
       "2   OraclePreston            55     19     True  2020-07-21  \n",
       "3  omnomenclature            56     17     True  2020-07-21  \n",
       "4  UlyssesCourier            61     33     True  2020-07-21  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at our dataset\n",
    "fantasy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2611 rows of data in this dataset.\n",
      "There are 9 columns of data in this dataset\n"
     ]
    }
   ],
   "source": [
    "# Confirm the size of our data\n",
    "print (f\"There are {fantasy_df.shape[0]} rows of data in this dataset.\")\n",
    "print (f\"There are {fantasy_df.shape[1]} columns of data in this dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title           0\n",
       "selftext        0\n",
       "subreddit       0\n",
       "created_utc     0\n",
       "author          0\n",
       "num_comments    0\n",
       "score           0\n",
       "is_self         0\n",
       "timestamp       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to ensure we have a complete dataset\n",
    "fantasy_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Scifi Subreddit\n",
    "Similar to the Fantasy subreddit, we determined that the scifi subreddit reaches 100 posts every 4 days or so, and our goal was for a dataframe of about 2,500 rows. So, we collected 280 days of data, which meant that from the 7,000 original rows, about 4,500 rows were dropped due to being duplicates, nontext posts, or removed or deleted posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=4d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=8d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=12d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=16d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=20d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=24d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=28d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=32d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=36d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=40d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=44d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=48d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=52d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=56d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=60d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=64d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=68d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=72d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=76d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=80d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=84d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=88d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=92d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=96d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=100d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=104d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=108d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=112d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=116d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=120d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=124d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=128d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=132d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=136d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=140d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=144d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=148d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=152d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=156d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=160d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=164d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=168d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=172d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=176d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=180d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=184d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=188d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=192d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=196d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=200d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=204d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=208d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=212d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=216d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=220d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=224d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=228d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=232d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=236d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=240d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=244d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=248d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=252d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=256d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=260d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=264d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=268d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=272d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=276d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=scifi&size=100&after=280d\n",
      "Query Complete!\n"
     ]
    }
   ],
   "source": [
    "scifi_df = query_pushshift(\"scifi\", day_window = 4, n = 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>is_self</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AI &amp;amp; Emotions</td>\n",
       "      <td>So lets talk AI, i know, how original. \\n\\nI h...</td>\n",
       "      <td>scifi</td>\n",
       "      <td>1595109322</td>\n",
       "      <td>VonBraun12</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-07-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Guess the book</td>\n",
       "      <td>Hi all can you help, I’m trying to get the nam...</td>\n",
       "      <td>scifi</td>\n",
       "      <td>1595115628</td>\n",
       "      <td>DarthKittens</td>\n",
       "      <td>36</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-07-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I want to play a game. Describe your favorite ...</td>\n",
       "      <td>I'll go first.  \"Lonely man blogs about monocu...</td>\n",
       "      <td>scifi</td>\n",
       "      <td>1595117078</td>\n",
       "      <td>MyMomSaysIAmCool</td>\n",
       "      <td>83</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-07-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zero Hours is an epic seven episode miniseries...</td>\n",
       "      <td>What does it mean for the world to end? Okay, ...</td>\n",
       "      <td>scifi</td>\n",
       "      <td>1595119454</td>\n",
       "      <td>ArthurDrakoni</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-07-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Help needed - I’m writing a whodunit detective...</td>\n",
       "      <td>So this is my idea, At the place of crime, the...</td>\n",
       "      <td>scifi</td>\n",
       "      <td>1595143575</td>\n",
       "      <td>gooodfella</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-07-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                                  AI &amp; Emotions   \n",
       "1                                     Guess the book   \n",
       "2  I want to play a game. Describe your favorite ...   \n",
       "3  Zero Hours is an epic seven episode miniseries...   \n",
       "4  Help needed - I’m writing a whodunit detective...   \n",
       "\n",
       "                                            selftext subreddit  created_utc  \\\n",
       "0  So lets talk AI, i know, how original. \\n\\nI h...     scifi   1595109322   \n",
       "1  Hi all can you help, I’m trying to get the nam...     scifi   1595115628   \n",
       "2  I'll go first.  \"Lonely man blogs about monocu...     scifi   1595117078   \n",
       "3  What does it mean for the world to end? Okay, ...     scifi   1595119454   \n",
       "4  So this is my idea, At the place of crime, the...     scifi   1595143575   \n",
       "\n",
       "             author  num_comments  score  is_self   timestamp  \n",
       "0        VonBraun12            26      3     True  2020-07-18  \n",
       "1      DarthKittens            36     10     True  2020-07-18  \n",
       "2  MyMomSaysIAmCool            83      7     True  2020-07-18  \n",
       "3     ArthurDrakoni             2      0     True  2020-07-18  \n",
       "4        gooodfella            10      0     True  2020-07-19  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the data\n",
    "scifi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2595 rows of data in this dataset.\n",
      "There are 9 columns of data in this dataset\n"
     ]
    }
   ],
   "source": [
    "# Confirm the size of our data\n",
    "print (f\"There are {scifi_df.shape[0]} rows of data in this dataset.\")\n",
    "print (f\"There are {scifi_df.shape[1]} columns of data in this dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title           0\n",
       "selftext        0\n",
       "subreddit       0\n",
       "created_utc     0\n",
       "author          0\n",
       "num_comments    0\n",
       "score           0\n",
       "is_self         0\n",
       "timestamp       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that we have a completed dataset\n",
    "scifi_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the Dataframes\n",
    "Next, we'll concatenate the 2 datasets, one on top of the other, into one large dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>is_self</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are NEWLY published and noticeably popula...</td>\n",
       "      <td>I've asked the same question last year I think...</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>1595292735</td>\n",
       "      <td>uera</td>\n",
       "      <td>68</td>\n",
       "      <td>37</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-07-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LF Recommendation: Fantasy with long travel ep...</td>\n",
       "      <td>Hi looking for recommendation for a top prefer...</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>1595295818</td>\n",
       "      <td>Overthrown77</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-07-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the best Fantasy book you've read that...</td>\n",
       "      <td>usually I don't enjoy something below four sta...</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>1595304562</td>\n",
       "      <td>OraclePreston</td>\n",
       "      <td>55</td>\n",
       "      <td>19</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Favorite fantasy names?</td>\n",
       "      <td>I love fantasy, and I also have a thing for na...</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>1595305376</td>\n",
       "      <td>omnomenclature</td>\n",
       "      <td>56</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anyone can recommend me a book without having ...</td>\n",
       "      <td>Idk how else to put the title but I really wan...</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>1595305716</td>\n",
       "      <td>UlyssesCourier</td>\n",
       "      <td>61</td>\n",
       "      <td>33</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-07-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  What are NEWLY published and noticeably popula...   \n",
       "1  LF Recommendation: Fantasy with long travel ep...   \n",
       "2  What is the best Fantasy book you've read that...   \n",
       "3                            Favorite fantasy names?   \n",
       "4  Anyone can recommend me a book without having ...   \n",
       "\n",
       "                                            selftext subreddit  created_utc  \\\n",
       "0  I've asked the same question last year I think...   Fantasy   1595292735   \n",
       "1  Hi looking for recommendation for a top prefer...   Fantasy   1595295818   \n",
       "2  usually I don't enjoy something below four sta...   Fantasy   1595304562   \n",
       "3  I love fantasy, and I also have a thing for na...   Fantasy   1595305376   \n",
       "4  Idk how else to put the title but I really wan...   Fantasy   1595305716   \n",
       "\n",
       "           author  num_comments  score  is_self   timestamp  \n",
       "0            uera            68     37     True  2020-07-20  \n",
       "1    Overthrown77            16      5     True  2020-07-20  \n",
       "2   OraclePreston            55     19     True  2020-07-21  \n",
       "3  omnomenclature            56     17     True  2020-07-21  \n",
       "4  UlyssesCourier            61     33     True  2020-07-21  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df = pd.concat([fantasy_df, scifi_df], axis = 0, ignore_index= True)\n",
    "# Reset the index so there are no repeats\n",
    "reddit_df.reset_index(drop = True, inplace = True)\n",
    "# Take a look at our data\n",
    "reddit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5206 rows of data in this dataset.\n",
      "There are 9 columns of data in this dataset\n"
     ]
    }
   ],
   "source": [
    "# Confirm the size of our data\n",
    "print (f\"There are {reddit_df.shape[0]} rows of data in this dataset.\")\n",
    "print (f\"There are {reddit_df.shape[1]} columns of data in this dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fantasy    2611\n",
       "scifi      2595\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that our 2 dataframes are in our new one\n",
    "reddit_df[\"subreddit\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export our Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export our dataframe, while not creating a new column from the index.\n",
    "reddit_df.to_csv(\"subreddits.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
